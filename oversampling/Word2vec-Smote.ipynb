{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f39c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade gensim -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f05f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc9ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaf7e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f773294f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c5c848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv=api.load('glove-twitter-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0f6f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.save('E:/Users/hashim/Documents/cse 19-23/4th yr/project/dataset/gsheets/vectors.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "551078da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.1418e-01, -1.9196e-01, -7.9963e-01,  9.1339e-01, -5.7061e-01,\n",
       "        7.1746e-01, -5.8979e-01, -5.1530e-01,  1.3453e+00, -2.0792e-01,\n",
       "        4.4555e-01,  2.4981e-01, -3.2020e+00,  3.5736e-01, -2.3593e-02,\n",
       "       -3.1158e-02,  3.7782e-01,  6.4447e-01,  1.2056e+00, -1.0553e-01,\n",
       "       -8.9697e-01, -7.9754e-01,  2.0239e-01, -1.0664e+00, -4.7167e-01,\n",
       "       -2.5953e-01,  1.1328e-01, -3.8142e-01,  2.0366e-03, -5.0261e-01,\n",
       "       -2.5197e-01, -8.4033e-02, -1.0015e+00, -8.6835e-01,  6.6201e-01,\n",
       "        2.6496e-01,  2.2570e-01, -3.3847e-01, -3.4739e-01,  6.2199e-01,\n",
       "       -1.3491e+00, -1.7497e-01, -1.1490e+00,  1.5144e-01,  1.1255e+00,\n",
       "       -6.2668e-01, -3.4274e-01, -3.4938e-01, -1.0806e+00,  6.0174e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv['apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e474e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "wv=KeyedVectors.load('E:/Users/hashim/Documents/cse 19-23/4th yr/project/dataset/gsheets/vectors.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d77c29f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.1418e-01 -1.9196e-01 -7.9963e-01  9.1339e-01 -5.7061e-01  7.1746e-01\n",
      " -5.8979e-01 -5.1530e-01  1.3453e+00 -2.0792e-01  4.4555e-01  2.4981e-01\n",
      " -3.2020e+00  3.5736e-01 -2.3593e-02 -3.1158e-02  3.7782e-01  6.4447e-01\n",
      "  1.2056e+00 -1.0553e-01 -8.9697e-01 -7.9754e-01  2.0239e-01 -1.0664e+00\n",
      " -4.7167e-01 -2.5953e-01  1.1328e-01 -3.8142e-01  2.0366e-03 -5.0261e-01\n",
      " -2.5197e-01 -8.4033e-02 -1.0015e+00 -8.6835e-01  6.6201e-01  2.6496e-01\n",
      "  2.2570e-01 -3.3847e-01 -3.4739e-01  6.2199e-01 -1.3491e+00 -1.7497e-01\n",
      " -1.1490e+00  1.5144e-01  1.1255e+00 -6.2668e-01 -3.4274e-01 -3.4938e-01\n",
      " -1.0806e+00  6.0174e-01]\n"
     ]
    }
   ],
   "source": [
    "print(wv['apple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "519e86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=pd.read_csv(\"E:/Users/hashim/Documents/cse 19-23/4th yr/project/dataset/gsheets/data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d8b5ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets=pd.read_csv(\"E:/Users/hashim/Documents/cse 19-23/4th yr/project/dataset/gsheets/oversam_data1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84b26030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(wv.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8997664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentvec(sent):\n",
    "    v_size=wv.vector_size\n",
    "    wv_res=np.zeros(v_size)\n",
    "    ctr=1\n",
    "    for w in sent:\n",
    "        if w in wv:\n",
    "            ctr+=1\n",
    "            wv_res+=wv[w]\n",
    "    wv_res/=ctr\n",
    "    return wv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70cfa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55fa79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be2356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdad3e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "\n",
    "\n",
    "    # print(doc)\n",
    "    # print(type(doc))\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() for word in doc ]\n",
    "\n",
    "    # print(mytokens)\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e5abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentvec(\"hello word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c872fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "stop_words=nlp.Defaults.stop_words\n",
    "#print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a616536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "punctuations = string.punctuation\n",
    "print(punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11175db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "211de833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(datasets['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dfa0d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['TOKENS'] = datasets['TEXT'].apply(spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6beba04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(datasets['TOKENS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf881ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4593a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['VEC'] = datasets['TOKENS'].apply(sentvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0634ea74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>TOKENS</th>\n",
       "      <th>VEC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your opinion about me? 1. Over 2. Jada 3. Kusr...</td>\n",
       "      <td>0</td>\n",
       "      <td>[opinion, 1, 2, jada, 3, kusruthi, 4, lovable,...</td>\n",
       "      <td>[0.16899942109982172, -0.028940506434688967, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's up? Do you want me to come online? If y...</td>\n",
       "      <td>0</td>\n",
       "      <td>[want, come, online, free, talk, �]</td>\n",
       "      <td>[0.19219833612442017, 0.4040516677002112, -0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So u workin overtime nigpun?</td>\n",
       "      <td>0</td>\n",
       "      <td>[u, workin, overtime, nigpun]</td>\n",
       "      <td>[-0.03244650363922119, 0.3589550070464611, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Also sir, i sent you an email about how to log...</td>\n",
       "      <td>0</td>\n",
       "      <td>[sir, send, email, log, usc, payment, portal, ...</td>\n",
       "      <td>[0.4800335671752691, 0.3625061314087361, -0.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please Stay At Home. To encourage the notion o...</td>\n",
       "      <td>1</td>\n",
       "      <td>[stay, home, encourage, notion, stay, home, ta...</td>\n",
       "      <td>[-0.07625343299542482, 0.26968545452333414, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  LABEL  \\\n",
       "0  Your opinion about me? 1. Over 2. Jada 3. Kusr...      0   \n",
       "1  What's up? Do you want me to come online? If y...      0   \n",
       "2                       So u workin overtime nigpun?      0   \n",
       "3  Also sir, i sent you an email about how to log...      0   \n",
       "4  Please Stay At Home. To encourage the notion o...      1   \n",
       "\n",
       "                                              TOKENS  \\\n",
       "0  [opinion, 1, 2, jada, 3, kusruthi, 4, lovable,...   \n",
       "1                [want, come, online, free, talk, �]   \n",
       "2                      [u, workin, overtime, nigpun]   \n",
       "3  [sir, send, email, log, usc, payment, portal, ...   \n",
       "4  [stay, home, encourage, notion, stay, home, ta...   \n",
       "\n",
       "                                                 VEC  \n",
       "0  [0.16899942109982172, -0.028940506434688967, -...  \n",
       "1  [0.19219833612442017, 0.4040516677002112, -0.4...  \n",
       "2  [-0.03244650363922119, 0.3589550070464611, 0.1...  \n",
       "3  [0.4800335671752691, 0.3625061314087361, -0.20...  \n",
       "4  [-0.07625343299542482, 0.26968545452333414, -0...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "676b2b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [0.16899942109982172, -0.028940506434688967, -...\n",
      "1       [0.19219833612442017, 0.4040516677002112, -0.4...\n",
      "2       [-0.03244650363922119, 0.3589550070464611, 0.1...\n",
      "3       [0.4800335671752691, 0.3625061314087361, -0.20...\n",
      "4       [-0.07625343299542482, 0.26968545452333414, -0...\n",
      "                              ...                        \n",
      "6035    [0.2167110651332353, 0.31791463906743694, -0.4...\n",
      "6036    [0.16138398945331572, 0.37906610276550057, -0....\n",
      "6037    [0.15237493334071978, 0.2721078539533274, -0.4...\n",
      "6038    [0.001691844815818163, 0.3896098964972995, -0....\n",
      "6039    [0.054755387971034415, 0.22956138705978027, -0...\n",
      "Name: VEC, Length: 6040, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(datasets['VEC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97bd6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = datasets['VEC'].to_list()\n",
    "Y1 = datasets['LABEL'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dfb6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.over_sampling import BorderlineSMOTE, SMOTE, ADASYN, SMOTENC, RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2983af",
   "metadata": {},
   "source": [
    "# SMOTE,ADASYN,BORDERLINE SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96700245",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=777)\n",
    "X, Y = sm.fit_resample(X1, Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "968b0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "asm = ADASYN(random_state=777)\n",
    "X, Y = asm.fit_resample(X1, Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4bc77bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm = BorderlineSMOTE()\n",
    "X, Y = bsm.fit_resample(X1,Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcff3c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fbecd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y,test_size = 0.20, random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f7885a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "# fit\n",
    "classifier.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41aad66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7761348005502063\n",
      "Logistic Regression Precision: 0.7761348005502063\n",
      "Logistic Regression Recall: 0.7761348005502063\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "predicted = classifier.predict(x_test)\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted,average='micro'))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25c925b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m mnb \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# fit\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m naive_model \u001b[38;5;241m=\u001b[39m \u001b[43mmnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# predict class\u001b[39;00m\n\u001b[0;32m      8\u001b[0m y_pred_class \u001b[38;5;241m=\u001b[39m mnb\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:690\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    688\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[1;32m--> 690\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:863\u001b[0m, in \u001b[0;36mMultinomialNB._count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;124;03m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m     \u001b[43mcheck_non_negative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMultinomialNB (input X)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1249\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1246\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# fit\n",
    "naive_model = mnb.fit(x_train,y_train)\n",
    "\n",
    "# predict class\n",
    "y_pred_class = mnb.predict(x_test)\n",
    "\n",
    "# printing the overall accuracy\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72a2063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9731774415405777\n",
      "0.9731774415405777\n",
      "0.9731774415405777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "rus_model=rf.fit(x_train,y_train)\n",
    "y_rus_class=rf.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test,y_rus_class))\n",
    "print(metrics.precision_score(y_test, y_rus_class,average='micro'))\n",
    "print(metrics.recall_score(y_test,y_rus_class,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600fb9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
